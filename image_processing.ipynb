{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8735ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(os.getcwd())\n",
    "cwd0 = './config/'\n",
    "sys.path.append(cwd0)\n",
    "\n",
    "import visualID_Eng as vID\n",
    "from visualID_Eng import fg,bg,hl,color\n",
    "vID.init(cwd0)\n",
    "\n",
    "import tools4pyPhysChem as t4pPC\n",
    "\n",
    "#cancel the \"last show-up\" behaviour of Jupyter notebooks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "__author__ = \"Simon Cayez, LPCNO / D√©partement G√©nie Physique (INSA Toulouse, France)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a90d06",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">\n",
    "  <b><u>Dataset Preparation</u>:<br>\n",
    "  Step 1 ‚Äì Image Processing</b>\n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a988a5",
   "metadata": {},
   "source": [
    "## Context\n",
    "  \n",
    "\n",
    "In this workshop, we will work on ¬µSAXS (Micro-Small-Angle X-Ray Scattering) data collected at the SOLEIL synchrotron, beamline SWING, from the following paper:\n",
    "\n",
    "Cha√¢bani, W.; Lyu, J.; Marcone, J.; Goldmann, C.; ten Veen, E. J. M.; Dumesnil, C.; Bizien, T.; Smallenburg, F.; Imp√©ror-Clerc, M.; Constantin, D.; Hamon, C. *Prismatic Confinement Induces Tunable Orientation in Plasmonic Supercrystals.* **ACS Nano** 2024, 18 (13), 9566-9575.  \n",
    "[https://doi.org/10.1021/acsnano.3c12799](https://doi.org/10.1021/acsnano.3c12799)  \n",
    "[pdf version](https://drive.google.com/file/d/1mMho8MjkwT_7HqI2QKEkG25SVLtqYgvI/view?usp=drive_link)\n",
    "\n",
    "The study investigates how to control the **orientation of plasmonic supercrystals** (assemblies of gold nanorods ‚âà60 nm long and ‚âà25 nm in diameter) by using **‚Äúprismatic confinement‚Äù** ‚Äî templates with polygonal (triangle, square, circle‚Ä¶) cross-sections.  \n",
    "These anisotropic gold nanoparticles were synthesized by a standard seed-mediated growth method, producing well-defined rods with tunable aspect ratios.\n",
    "\n",
    "Prismatic templates made of PDMS were filled with a **liquid suspension of nanorods**, then the solvent was removed by **evaporation-induced self-assembly (EISA)**.  \n",
    "This confinement + EISA process drives the rods to organize into **oriented supercrystals** whose texture depends on the template geometry.  \n",
    "The resulting structures were characterized by **¬µSAXS at a synchrotron** to reveal domain orientation and defects at the ensemble scale.\n",
    "\n",
    "\n",
    "- **Prismatic templates** (PDMS with polygonal cavities) combined with **evaporation-induced self-assembly** enable reproducible orientation of anisotropic nanoparticles into supercrystals.  \n",
    "- **Each edge of the cavity defines a monodomain orientation**; controlling the cavity geometry = controlling the texture of the supercrystal.  \n",
    "- **¬µSAXS at a synchrotron** bridges the gap between local (SEM) and ensemble (full SAXS) characterization ‚Äî key for understanding domain orientation and defects.  \n",
    "- This combined approach provides a **scalable, low-cost way to design metasurfaces** with tunable optical properties.  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0ded1",
   "metadata": {},
   "source": [
    "<!-- Tableau pour l'image principale, sans bordures -->\n",
    "<table style=\"border-collapse:collapse; border:none; margin-left:auto; margin-right:auto;\">\n",
    "  <tr>\n",
    "    <td style=\"text-align:center; border:none;\">\n",
    "      <img src=\"figures/fig0.png\" width=\"800\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"border-collapse:collapse; border:none; margin-left:auto; margin-right:auto; width:800px;\">\n",
    "  <tr>\n",
    "    <td style=\"text-align:justify; font-size:14px; border:none;\">\n",
    "      <i>\n",
    "        <b>Fig. 0. A)</b>  Schematic view of the templated EISA process.<br><br>\n",
    "        <b>B)</b> Schematic description of the geometry and size of microcavities<br>\n",
    "        <b>C)</b> Optical microscopy image of a superlattice of\n",
    "triangular SCs obtained after template-assisted self-assembly and peeling off the PDMS\n",
    "template. The red frame shows the typical footprint of the conventional SAXS beam and the\n",
    "blue one that of the ŒºSAXS beam, which also corresponds to the size of an SEM image.<br>\n",
    "        <b>D-E)</b> SEM images of an AuNR triangular geometrys.<br>\n",
    "        <b>E)</b> Au Nanorods organization in the mold<br>\n",
    "        <b>F)</b> Two-dimensional SAXS images acquired on different zones of the sample consisting of AuNR\n",
    "supercrystals with different cross-section.\n",
    "      </i>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77f966",
   "metadata": {},
   "source": [
    "We will work with a dataset of **1800 images** in **3 folders** named **\"circle\", \"triangle\" and \"square\"** with around 600 ¬µSAXS images for each geometry.  The aim is to **prepare the dataset** in order to use it for **deep learning** image **classification** with a 2D Convolutional Network.  \n",
    "Building the dataset is a key point for the success of all machine learning processes. It is common to obtain bad predictions due to poor data preparation.\n",
    "The steps will be:  \n",
    "\n",
    "\n",
    "- **Extract** images from structured *.nxs or *.h5 files  \n",
    "- Build **NumPy array**s containing images  \n",
    "- **Reshape** the NumPy arrays  \n",
    "- Explore the dataset by sample **image visualization** \n",
    "- Explore and adapt **pixel values** \n",
    "- **Crop** images  \n",
    "- Visualize the dataset as a **video**  \n",
    "- **Normalize** pixels in the range 0‚Äì1  \n",
    "- **Resize** images  \n",
    "- **Concatenate** the data from circle, square, and triangle to build X  \n",
    "- Create a **labels** array  \n",
    "- **Shuffle** the data  \n",
    "- **Split** the data into **train and test** sets  \n",
    "- Prepare a **Convolutional Neural Network**  \n",
    "- **Train** it  \n",
    "- Make **predictions** on the test dataset  \n",
    "- **Evaluate** the quality of the model  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ab379",
   "metadata": {},
   "source": [
    "In our dataset, we have **three classes** corresponding to the mold geometries:  \n",
    "\n",
    "- `circle`  \n",
    "- `triangle`  \n",
    "- `square`  \n",
    "\n",
    "In this workshop, we will process each class **separately** to explore and manipulate the images.  \n",
    "In the  notebook [`dataset_creation.ipynb`](dataset_creation.ipynb), we will **combine all classes** to build a complete dataset suitable for training a neural network.\n",
    "\n",
    "\n",
    "### Workflow Roadmap\n",
    "\n",
    "The figures below provides a visual **roadmap** of the steps we will follow during the workshop.  \n",
    "Each block corresponds to a key stage in the data preparation.  \n",
    "Variable names, functions, and loops that you will encounter in the notebook are already indicated inside the diagrams.  \n",
    "\n",
    "This roadmap will help you:\n",
    "- Understand the overall workflow  \n",
    "- See how individual steps (data extraction, reshaping, visualization, normalization, model building, training, evaluation‚Ä¶) connect to each other,\n",
    "- Quickly locate where a variable or function will be used in the code.\n",
    "\n",
    "You can refer back to this roadmap at any time as you progress through the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fa7c69",
   "metadata": {},
   "source": [
    "<table style=\"border-collapse:collapse; border:none; margin-left:auto; margin-right:auto;\">\n",
    "  <tr>\n",
    "    <td style=\"text-align:center; border:none;\">\n",
    "      <img src=\"figures/fig7.png\" width=\"450\">\n",
    "    </td>\n",
    "    <td style=\"text-align:center; border:none;\">\n",
    "      <img src=\"figures/fig8.png\" width=\"450\">\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b512b4",
   "metadata": {},
   "source": [
    "## 1- Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e60362",
   "metadata": {},
   "source": [
    "\n",
    "In synchrotron facilities, experimental data are stored in **NeXus (`.nxs`) files**, which are based on the HDF5 format.  \n",
    "These files contain a large amount of structured information (metadata, instrument settings, measurement results, etc.).  \n",
    "\n",
    "For this workshop, we are interested only in the **images** recorded during the experiment.  \n",
    "To simplify the workflow, we used a helper function called `extract_nxs_folder` (defined in `extract.py`).  \n",
    "This function reads all the **`.nxs` files** inside a specified folder and **extracts** the corresponding images into **NumPy arrays** that we can process further.\n",
    "\n",
    "The full process is detailed in the notebook [nxs_extraction.ipynb](nxs_extraction.ipynb)  \n",
    "\n",
    "With this [example of *.nxs file](https://drive.google.com/file/d/1AVqtR9f7KmtOwyNWw4nsCeyT0ASxG2IW/view?usp=drive_link) , you can quickly **preview the content of a `.nxs`/`.h5` file without writing code**, you can use the free online viewer provided by the HDF Group: [https://myhdf5.hdfgroup.org/](https://myhdf5.hdfgroup.org/).  \n",
    "  \n",
    "A small sample of  original `*.nxs files` is available at this [link](https://drive.google.com/drive/folders/1r7WzPfk0DzZjrfgaC5OcpNfCHPYGTvFh?usp=drive_link) for a future test of  [nxs_extraction.ipynb](nxs_extraction.ipynb)  \n",
    "\n",
    "To avoid to manipulate large amont of heavy `*.nxs` files, all the conversion were done before the workshop. We will then start from Numpy arrays.  \n",
    "For the firsts steps <u>download only `square_raw.npy` and place it in the folder `data`</u>.   \n",
    "\n",
    "- `square_raw.npy`[download](https://drive.google.com/file/d/11VUCyEgwYiCDk1qwRf7gep7PZEcbfTy3/view?usp=drive_link)\n",
    "- `triangle_raw.npy`[download](https://drive.google.com/file/d/1Ym_e5zN9spUv9dv5-8SNUtwajLQzXKeW/view?usp=drive_link)\n",
    "- `circle_raw.npy`[download](https://drive.google.com/file/d/1cAirdyB0nsuZEGLMetmh3y2oklF8PNg9/view?usp=drive_link)\n",
    "\n",
    "> ‚ö†Ô∏è When downloading, Google Drive may display a warning message:  \n",
    "> *\"Google Drive cannot scan this file for viruses. Do you want to download anyway?\"*  \n",
    "> The file is large (XX‚ÄØMB), so this is normal. **Please trust the source and continue with the download.**  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c116f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "geometry = 'square'\n",
    "file_path = f\"data/{geometry}_raw.npy\"\n",
    "data_raw = np.load(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb605e3",
   "metadata": {},
   "source": [
    "## 2 Explore data format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2910303",
   "metadata": {},
   "source": [
    "### 2-1 Shape and dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1271ff0",
   "metadata": {},
   "source": [
    "We first inspect the **number of dimensions** and the **shape** of the NumPy array to understand its structure (how many images and their size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7381dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of dimensions and the shape of the array\n",
    "print(f\"Number of dimensions : {data_raw.ndim}\")\n",
    "print(f\"Shape  : {data_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a78122",
   "metadata": {},
   "source": [
    "The loaded NumPy array has shape **(n, 1083, 1035)**:\n",
    "\n",
    "- **n** = number of images  \n",
    "- **1083** = image height (pixels)  \n",
    "- **1035** = image width (pixels)\n",
    "\n",
    "It is therefore a **3-D** array where each slice along the first axis is one image of **size 1083√ó1035 pixels**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cbfcf",
   "metadata": {},
   "source": [
    "In this section, we will focus on **visualizing the ¬µSAXS images** we extracted and preprocessed.  \n",
    "\n",
    "Since the dataset can contain **large numbers of high-resolution images**, it is important to explore them efficiently and to check for any unexpected artifacts or anomalies.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b842813",
   "metadata": {},
   "source": [
    "### 2-2 Plot images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c691e",
   "metadata": {},
   "source": [
    "\n",
    "We will use **Matplotlib**, a Python library for plotting graphs and displaying images, to visualize our dataset.  \n",
    "\n",
    "Since `first_channels` is a NumPy array containing multiple images, we **slice the array** to select only the first image (`index 0`) for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Display the first image in the first_channels array\n",
    "# raw_data[0, :, :] selects the first image (all rows and columns)\n",
    "# cmap='gray' ensures the image is shown in grayscale\n",
    "ax.imshow(data_raw[0, :, :],cmap='gray')\n",
    "ax.set_title(\"First image raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcaf688",
   "metadata": {},
   "source": [
    "We can also display **multiple images side by side** to compare them easily.  \n",
    "Here, we will show the first three images from `first_channels` using subplots in Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ecd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 1 row and 3 columns of subplots\n",
    "# figsize=(15,5) sets the width and height of the figure in inches\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "\n",
    "# Loop over the first three images\n",
    "for i in range(3):\n",
    "    # Display the i-th image in grayscale on the corresponding subplot\n",
    "    axes[i].imshow(data_raw[i, :, :],cmap='gray')\n",
    "    # Add a title to each subplot\n",
    "    axes[i].set_title(f\"Image {i} raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107d7b4d",
   "metadata": {},
   "source": [
    "On the images we just plotted, you may notice that the scattering patterns are **hard to see**: most of the pixels have relatively low intensity values, while a few pixels are very bright.  \n",
    "\n",
    "In SAXS experiments, the intensity of scattered X-rays can **span several orders of magnitude**. Using a **logarithmic scale** allows us to:\n",
    "\n",
    "- Better visualize **both low and high intensity regions** in the same image  \n",
    "- Highlight subtle features in the scattering patterns that would otherwise be invisible  \n",
    "\n",
    "Next, we will apply a logarithmic transformation to the images to make the structures more apparent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40bbb6f",
   "metadata": {},
   "source": [
    "### 2-3- Log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99907ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "for i in range(3):\n",
    "    # np.log1p(x) computes log(1 + x) to avoid log(0) and enhance contrast\n",
    "    axes[i].imshow(np.log1p(data_raw[i, :, :]),cmap='gray') \n",
    "    axes[i].set_title(f\"Log image {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e4056a",
   "metadata": {},
   "source": [
    "#### 2-3-1- Apply Logarithmic Transformation to the Data\n",
    "\n",
    "So far, we have only **visualized** the images using a logarithmic scale, but the underlying NumPy array **has not been modified**.  \n",
    "\n",
    "To enhance contrast and better handle the wide range of intensities in ¬µSAXS images, we will now **apply a logarithmic transformation directly to the NumPy array**.  \n",
    "This will update the data itself, so subsequent processing (normalization, resizing, or feeding into a neural network) will use the transformed values.  \n",
    "We typically use `np.log1p()` to safely compute `log(1 + x)`, which avoids issues with zero-intensity pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc61f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply a logarithmic transformation directly to the NumPy array\n",
    "data_log = np.log1p(data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14f651",
   "metadata": {},
   "source": [
    "#### 2-3-2- Image statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c8bfe",
   "metadata": {},
   "source": [
    "##### üìù Exercise: Print Image Statistics\n",
    "\n",
    "**Goal:** Create a function that prints the **minimum, maximum, mean, and median** pixel values of a selected image in a dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `print_image_stats`\n",
    "- **Arguments:**\n",
    "  - `images` : a NumPy array of shape `(n_images, width, height)`  \n",
    "  - `image_index` : the index of the image to analyze (default: 0)\n",
    "- **Returns:**  \n",
    "  - Nothing, only prints the statistics in a clear format\n",
    "\n",
    "**Steps:**\n",
    "1. Select the image at `image_index` from `images`.\n",
    "2. Compute the `min`, `max`, `mean`, and `median` values of the image.\n",
    "3. Print them in a readable table format.\n",
    "\n",
    "Implement the function below in a file called `visualization.py ` saved in the **current directory**.  \n",
    "\n",
    "\n",
    "**Example of expected print output (numbers are illustrative):**\n",
    "<pre>\n",
    "Statistic Value\n",
    "Min 0.0000  \n",
    "Max 123.4567  \n",
    "Mean 12.3456  \n",
    "Median 10.0000  \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce94feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizualisation import print_image_stats\n",
    "\n",
    "print_image_stats(data_raw, image_index=0)\n",
    "print_image_stats(data_log, image_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53025e4",
   "metadata": {},
   "source": [
    "### 2-4 Check all images with a video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f1dc6",
   "metadata": {},
   "source": [
    "##### üìù Exercise: Create a Video from Images\n",
    "\n",
    "**Goal:** Create a function that converts a sequence of images into a **video file** for fast visualization of the dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `create_video_from_images`  \n",
    "- **Arguments:**\n",
    "  - `images` : a NumPy array of shape `(n_images, height, width)`  \n",
    "  - `output_path` : path where the video file will be saved (default `'output_video.mp4'`)  \n",
    "  - `fps` : frames per second (speed of the video, default `5`)\n",
    "- **Returns:**  \n",
    "  - Nothing, the function should save a video file to `output_path`  \n",
    "- **Save the function in:** `visualization.py`\n",
    "\n",
    "**Steps:**\n",
    "1. Read the number of images and their dimensions from the array.  \n",
    "2. Create a `cv2.VideoWriter` object with the correct codec, frame size, and FPS.  \n",
    "3. Loop over the images, normalize pixel values to 0‚Äì255, convert to `uint8`, and write each frame to the video.  \n",
    "4. Release the `VideoWriter` and print a confirmation with the video details.\n",
    "\n",
    "**Example usage:**\n",
    "\n",
    "```python\n",
    "# Create a video from the log-transformed dataset\n",
    "create_video_from_images(data_log, output_path='xxx.mp4', fps=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d596f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizualisation import create_video_from_images\n",
    "create_video_from_images(data_log, f\"data/{geometry}_video.mp4\", fps=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97bbff1",
   "metadata": {},
   "source": [
    "## 3- Crop images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f271318",
   "metadata": {},
   "source": [
    "### 3-1 Select crop coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f972f",
   "metadata": {},
   "source": [
    "By watching the video, we can see that the scattering signal always appears in the **same region** of the images.  \n",
    "To reduce the dataset size and focus the model on the relevant features, we will **crop each image** to keep only the region containing the signal.\n",
    "\n",
    "First, let's **visualize the first image** to decide the cropping boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_log[0,:, :],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb81c7",
   "metadata": {},
   "source": [
    "**Visually inspect different slices** of the first image by trying various ranges for the `x` (columns) and `y` (rows) coordinates.  \n",
    "\n",
    "Crop image of index zero to obtain a square image of arond 240x240 pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ea051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the crop ranges\n",
    "rows = slice(560, 800)  # y-range\n",
    "cols = slice(130, 370)  # x-range\n",
    "\n",
    "# Visualize the cropped region of the first image\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_log[0, rows, cols], cmap='gray')\n",
    "ax.set_title(\"Cropped region of first image\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb9740",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crop = data_log[:,rows, cols]\n",
    "print(\"Before Crop :\", data_log.shape)\n",
    "print(\"After Crop :\", data_crop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before Crop :\", data_log.shape)\n",
    "print(\"After Crop :\", data_crop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f9009f",
   "metadata": {},
   "source": [
    "## 4- Pixels Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44a965",
   "metadata": {},
   "source": [
    "In this section, we will **explore the distribution of pixel values** in our images with statistics and histograms.   \n",
    "\n",
    "This step is important because:  \n",
    "\n",
    "- It helps us **identify extreme values (outliers)** that may distort the training of a neural network.  \n",
    "- It indicates whether **pre-processing** (normalization, clipping, or outlier removal) might be necessary before training.  \n",
    "- It provides a clearer picture of the **intensity ranges** that the model will have to handle.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac37a8",
   "metadata": {},
   "source": [
    "### 4-1- Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4224b7",
   "metadata": {},
   "source": [
    "We will now reuse the previously defined `print_image_stats` function to inspect our image of index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizualisation import print_image_stats\n",
    "print_image_stats(data_crop, image_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2c46f",
   "metadata": {},
   "source": [
    "\n",
    "From the computed statistics we observe:\n",
    "\n",
    "- The **mean**  and **median**  are much closer to the **minimum** value  than to the **maximum** value.  \n",
    "- The **mean** is also noticeably higher than the **median**.  \n",
    "\n",
    "This suggests that the pixel value distribution is not balanced. We can verify this by plotting the histogram of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816c695d",
   "metadata": {},
   "source": [
    "### 4-2 Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172d2fd",
   "metadata": {},
   "source": [
    "##### üìù Exercise: Plot Image Histogram\n",
    "\n",
    "**Goal:** Create a function that plots the **histogram of pixel values** of a selected image from a dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `plot_image_histogram`  \n",
    "- **Arguments:**\n",
    "  - `data` : a NumPy array of shape `(n_images, height, width)`  \n",
    "  - `image_index` : index of the image to plot (default: `0`)  \n",
    "  - `bins` : number of bins for the histogram (default: `100`)  \n",
    "- **Returns:**  \n",
    "  - Nothing, the function should display the histogram of pixel values.  \n",
    "- **Save the function in:** `visualization.py`\n",
    "\n",
    "**Steps:**\n",
    "1. Select the 2D image at `image_index` from `data`.  \n",
    "2. Flatten the image with `.ravel()` to get all pixel values in a 1D array.  \n",
    "3. Plot the histogram using `matplotlib.pyplot.hist`.  \n",
    "4. Add clear axis labels (‚ÄúPixel value‚Äù / ‚ÄúNumber of pixels‚Äù) and a descriptive title indicating the image index.  \n",
    "5. Display the plot with `plt.show()`.\n",
    "\n",
    "**Example usage:**\n",
    "\n",
    "```python\n",
    "# Plot the histogram of the first cropped image\n",
    "plot_image_histogram(data_crop, image_index=0, bins=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bfea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizualisation import plot_image_histogram\n",
    "plot_image_histogram(data_crop) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04dd17",
   "metadata": {},
   "source": [
    "We observe that there are a few high pixel values in the image.  \n",
    "\n",
    "Try to **locate these outliers** by plotting red markers on pixels that exceed a chosen threshold in the first image.  \n",
    "You will likely need to **zoom in** on the image to clearly see the high-value pixels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1bfbc4",
   "metadata": {},
   "source": [
    "### 4-3- Vizualise outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed20a33",
   "metadata": {},
   "source": [
    "\n",
    "##### üìù Exercise: Highlight Pixels Above Threshold\n",
    "\n",
    "**Goal:** Create a function that displays a 2D image and **marks all pixels above a given threshold** in red.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `show_image_with_pixels_over_threshold`  \n",
    "- **Arguments:**\n",
    "  - `image` : a 2D NumPy array of shape `(height, width)`  \n",
    "  - `threshold` : pixel value threshold to highlight  \n",
    "- **Returns:**  \n",
    "  - Nothing, the function should display the image with marked pixels and print the number of pixels above the threshold.  \n",
    "- **Save the function in:** `visualization.py`\n",
    "\n",
    "**Steps:**\n",
    "1. Identify the coordinates of all pixels where the value is greater than `threshold`.  \n",
    "2. Plot the image using `matplotlib.pyplot.imshow` with a grayscale colormap.  \n",
    "3. Overlay the detected pixels as red markers using `plt.scatter`.  \n",
    "4. Add a title indicating the threshold value, hide axes, and include a legend.  \n",
    "5. Display the plot and print the total number of pixels above the threshold.  \n",
    "\n",
    "**Example usage:**\n",
    "\n",
    "```python\n",
    "# Highlight pixels above threshold 20 in the first cropped image\n",
    "show_image_with_pixels_over_threshold(data_crop[0], threshold=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizualisation import show_image_with_pixels_over_threshold\n",
    "threshold = 10\n",
    "show_image_with_pixels_over_threshold(data_crop[0,:,:], threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071fbc3c",
   "metadata": {},
   "source": [
    "We can now **localize the strong pixel values** in a single image.  \n",
    "However, analyzing just one picture may not be representative of the dataset.  \n",
    "\n",
    "We will display **6 images** by passing **6 random indices** to your function to explore high-value pixels across multiple images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf5fce",
   "metadata": {},
   "source": [
    "To get a representative view of the dataset, we don‚Äôt want to display the first 6 images or just any sequential subset.  \n",
    "Instead, we **randomly select 6 image indices**. This ensures that we visualize a variety of images across the dataset and can inspect different features, like high-value pixels, across multiple samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01754dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Randomly select 6 indices from the first dimension\n",
    "n_images = data_raw.shape[0]\n",
    "random_indices = random.sample(range(n_images), 6)\n",
    "print(random_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7f8dc9",
   "metadata": {},
   "source": [
    "##### üìù Exercise: Display 6 Random Images with Optional Threshold\n",
    "\n",
    "**Goal:** Create a function that displays **6 images** in a 2√ó3 grid. Optionally, mark the pixels above a given threshold in red.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- **Function name:** `plot_6images`  \n",
    "- **Arguments:**\n",
    "  - `data` : 3D NumPy array of shape `(n_images, width, height)`  \n",
    "  - `indices` : list of 6 integer indices to display  \n",
    "  - `threshold` : float, optional, pixels above this value are highlighted \n",
    "  - `show_threshold` : bool, optional, whether to show pixels above threshold  \n",
    "  - `figsize` : tuple, optional, size of the figure \n",
    "  - `cmap` : str, optional, colormap to use  \n",
    "\n",
    "- **Returns:**  \n",
    "  - Nothing; displays a 2√ó3 grid of images, optionally highlighting pixels above the threshold.\n",
    "\n",
    "- **Steps:**\n",
    "1. Check that `indices` contains exactly 6 elements.  \n",
    "2. Loop over the 6 selected indices and plot each image in a subplot.  \n",
    "3. If `show_threshold` is True and `threshold` is set, overlay red markers on pixels exceeding the threshold.  \n",
    "4. Remove axes and set titles for readability.  \n",
    "5. Use `plt.tight_layout()` and `plt.show()` to display the figure cleanly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a76f57",
   "metadata": {},
   "source": [
    "Check on 6 random images with a plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizualisation import plot_6images\n",
    "plot_6images(data_crop, random_indices, threshold=threshold, show_threshold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad302e",
   "metadata": {},
   "source": [
    "### 4-4- Clip pixels values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab36696f",
   "metadata": {},
   "source": [
    "We want an histogram with a good repartition on all the values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8615e92",
   "metadata": {},
   "source": [
    "Most of the pixels above the chosen threshold are located near the **beamstop**, likely originating from the **direct beam**.\n",
    "\n",
    "In SAXS experiments, the meaningful scattering information is **not expected in this region**, so these extreme values can distort further analysis.\n",
    "\n",
    "To handle this, we will **cap the pixel values** at the threshold using `numpy.clip`, ensuring that all values above the threshold are set to the threshold value. This reduces the influence of outliers while keeping the rest of the image intact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7136cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clip = np.clip(data_crop, min = None, max = threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ce8da",
   "metadata": {},
   "source": [
    "We will now **check the effect of clipping** by using the previously defined functions `print_image_stats` and `plot_image_histogram`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before Clip')\n",
    "print_image_stats(data_crop, image_index=0)\n",
    "print('After Clip')\n",
    "print_image_stats(data_clip, image_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8015c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vizualisation import plot_image_histogram\n",
    "plot_image_histogram(data_clip) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd65f804",
   "metadata": {},
   "source": [
    "After clipping, the data distribution appears more **balanced**, meaning the histogram is more **centered** and the extreme values no longer dominate.  \n",
    "This makes the dataset easier to interpret and more suitable for training a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d620cc9",
   "metadata": {},
   "source": [
    "### 4-5- Normalize pixels values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd13e81",
   "metadata": {},
   "source": [
    "**Normalization** is the process of rescaling data to a standard range, usually between 0 and 1. For images, this means dividing pixel values by a reference value, such as the maximum value of the image or a fixed threshold.\n",
    "\n",
    "For **deep learning** normlization is benefic because:   \n",
    "\n",
    "- Neural networks perform better when inputs are on a **similar scale**.  \n",
    "- It helps **stabilize training** and speeds up **convergence**.  \n",
    "- Prevents **extreme values** (outliers) from dominating the learning process.  \n",
    "\n",
    "\n",
    "In this dataset, we normalize each image individually to make the data suitable for training models that predict or classify based on pixel intensity patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the max of each image along (1,2) axes\n",
    "data_norm = data_clip / threshold\n",
    "\n",
    "print(data_clip.shape)\n",
    "for i in random_indices:\n",
    "    print_image_stats(data_norm, image_index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b0993",
   "metadata": {},
   "source": [
    "## 5- Resize image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051cd10d",
   "metadata": {},
   "source": [
    "For CNNs, **resolution is not a key point** ; smaller images allow handling a **larger number of images** with the same memory footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae27ad6",
   "metadata": {},
   "source": [
    "##### üìù Exercise: Resize Images\n",
    "\n",
    "**Goal:** Reduce all images in `data_norm` to **128√ó128 pixels** using `skimage.transform`.  \n",
    "\n",
    "**Instructions:**  \n",
    "\n",
    "- Process the 3D array `data_norm` so that each image has shape `(128, 128)`.  \n",
    "- Verify the result by printing the shape of the new array.  \n",
    "\n",
    "**Hints:**  \n",
    "- Use `skimage.transform.resize`.  \n",
    "- Preserve the number of images.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41199531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "# data : (N, H, W)\n",
    "new_h, new_w = 128, 128\n",
    "data_resized = resize(\n",
    "    data_norm, \n",
    "    (data_norm.shape[0], new_h, new_w),  # m√™me nombre d'images\n",
    "    order=1,                       # bilinear interpolation\n",
    "    preserve_range=True,            # garde les valeurs originales (pas normalis√©)\n",
    "    anti_aliasing=True\n",
    ")\n",
    "print(data_resized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8716dc83",
   "metadata": {},
   "source": [
    "## 5- Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7bc159",
   "metadata": {},
   "source": [
    "Now we have complete the process of image dataset preparation for one of the classes. We will run this notebook for the 2 other shapes (for more a for loop would be required, not done there for keeping notebook readeablity). \n",
    "This process will of course vary with other images dataset, but the main ideas remain the same:\n",
    "- keep only part of the image that can be interpreted by deep learning model:\n",
    "    - by cropping the region of interest when possible\n",
    "    - remove outlliers pixels values\n",
    "- convert pixels values to have a good balance\n",
    "- apply transformation if necessary as lo here\n",
    "- normalize the value between 0 and 1\n",
    "\n",
    "In this dataset all images were coming from the same source but sometime operations of uniformization on size or puxel values are required. \n",
    "Noww we will save the data as _data_preprocess.npy to continue by assembling them in a single dataset in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84a8b2",
   "metadata": {},
   "source": [
    "We have now completed the **image dataset preparation** for one of the classes.  \n",
    "The same steps can be repeated for the other shapes (or automated with a loop), but we avoided this here to keep the notebook readable.\n",
    "\n",
    "### Key Steps Applied:\n",
    "\n",
    "- **Focus on relevant regions:**  \n",
    "  - Crop images to keep only the region containing meaningful signal.  \n",
    "  - Remove outlier pixel values (extremely high pixels near the beamstop) to avoid biasing the model.\n",
    "\n",
    "- **Balance pixel values:**  \n",
    "  - Apply logarithmic transformations to better distribute intensity values.  \n",
    "  - Normalize pixel values (between 0 and 1, or using the maximum per image) to ensure consistency across the dataset.\n",
    "\n",
    "- **Resize images:**  \n",
    "  - Reduce image dimensions (here to 128√ó128) to allow faster processing and handling of larger datasets in deep learning.\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- Although all images in this dataset come from the same source, in other datasets additional uniformization may be necessary:\n",
    "  - Standardizing image sizes\n",
    "  - Normalizing intensity ranges\n",
    "  - Removing noise or artifacts\n",
    "\n",
    "\n",
    "Finally, the processed images are **saved** in `geometry_data_preprocess.npy`, where `geometry` is one of `'circle'`, `'square'`, or `'triangle'`.  \n",
    "In the  [dataset_creation_processed_data.ipynb](./dataset_creation_processed_data.ipynb), we will use these three files to assemble the full dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f\"data/{geometry}_data_preprocess.npy\"\n",
    "np.save(save_path, data_resized)\n",
    "print(f\"File saved in {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f941cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vID.end(cwd0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donnees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
