{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "print(os.getcwd())\n",
    "cwd0 = './config/'\n",
    "sys.path.append(cwd0)\n",
    "\n",
    "import visualID_Eng as vID\n",
    "from visualID_Eng import fg,bg,hl,color\n",
    "vID.init(cwd0)\n",
    "\n",
    "import tools4pyPhysChem as t4pPC\n",
    "\n",
    "#cancel the \"last show-up\" behaviour of Jupyter notebooks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "__author__ = \"Simon Cayez, LPCNO / Département Génie Physique (INSA Toulouse, France)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f129d2",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align: center;\">\n",
    "  <b><u>Dataset Preparation</u>:<br>\n",
    "  Step 2 – Full Dataset Assembly and CNN Training</b>\n",
    "</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d0f47",
   "metadata": {},
   "source": [
    "In the previous notebook, we processed the images for each shape separately, preparing them for deep learning.  \n",
    "In this notebook, we will **aggregate the three classes** (`circle`, `triangle`, `square`) into a single dataset, **assign labels**, **shuffle and normalize** the data, and **split it into training and test sets**.  \n",
    "\n",
    "Finally, we will **train a 2D CNN** on this dataset and **make predictions**.  \n",
    "This notebook continues directly from the previous one: [Step 1 – Image Processing](image_processing.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7b572",
   "metadata": {},
   "source": [
    "## 1- Create Numpy array datasets with all geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c21f3a",
   "metadata": {},
   "source": [
    "### 1-1- Images array (X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26900eda",
   "metadata": {},
   "source": [
    "#### 1-1-1- Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f31026",
   "metadata": {},
   "source": [
    "Load the preprocessed images for each shape as NumPy arrays and check their dimensions. Use `np.load`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d980d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_dir = '../data/mini_dataset/mini_dataset/'\n",
    "\n",
    "path_circle = os.path.join(base_dir,\"circle/circle_data_preprocess.npy\")\n",
    "path_square = os.path.join(base_dir,\"square/square_data_preprocess.npy\")\n",
    "path_triangle = os.path.join(base_dir,\"triangle/triangle_data_preprocess.npy\")\n",
    "\n",
    "\n",
    "circle = np.load(path_circle)\n",
    "square = np.load(path_square)    # (N2, 128, 128)\n",
    "triangle = np.load(path_triangle)# (N3, 128, 128\n",
    "\n",
    "print(circle.shape)\n",
    "print(square.shape)\n",
    "print(triangle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7242e0b",
   "metadata": {},
   "source": [
    "#### 1-1-2- Concatenate arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa98ea",
   "metadata": {},
   "source": [
    "**concatenate** the three image arrays (`circle`, `square`, `triangle`) along the first axis to combine them into a single dataset `X`.\n",
    "\n",
    "- Before concatenation:  \n",
    "  - `circle` : shape `(a, 128, 128)`  \n",
    "  - `square` : shape `(b, 128, 128)`  \n",
    "  - `triangle`: shape `(c, 128, 128)`  \n",
    "\n",
    "- After concatenation:  \n",
    "  - `X` : shape `(a+b+c, 128, 128)`  \n",
    "\n",
    "This combined array `X` now contains **all images from the three classes** in one single dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08740197",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([circle, square, triangle], axis=0) \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f424694",
   "metadata": {},
   "source": [
    "#### 1-2- Labels array (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeb6776",
   "metadata": {},
   "source": [
    "#### 1-2-1- Create labels arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c099b22",
   "metadata": {},
   "source": [
    "Create the **labels** for each image set.  \n",
    "In a classification problem, a **label** is a numeric value representing the class of each sample.  \n",
    "\n",
    "- All circle images are assigned the label `0`  \n",
    "- All square images are assigned the label `1`  \n",
    "- All triangle images are assigned the label `2`  \n",
    " **create the corresponding labels** for each shape.  \n",
    "For this, we build three NumPy arrays:  \n",
    "\n",
    "- One filled with `0` for circles (`len(circle)` elements)  \n",
    "- One filled with `1` for squares (`len(square)` elements)  \n",
    "- One filled with `2` for triangles (`len(triangle)` elements)  \n",
    "\n",
    "These arrays give each image its **class label** (circle, square, triangle) and will be combined with the image data in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c8eeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_circle = np.zeros(len(circle), dtype=int)           # classe 0\n",
    "y_square = np.ones(len(square), dtype=int)            # classe 1\n",
    "y_triangle = np.full(len(triangle), 2, dtype=int) \n",
    "\n",
    "print(y_circle.shape)\n",
    "print(y_square.shape)\n",
    "print(y_triangle.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab5ee2",
   "metadata": {},
   "source": [
    "#### 1-1-2- Concatenate arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591eb412",
   "metadata": {},
   "source": [
    "**concatenate** the three label arrays (`y_circle`, `y_square`, `y_triangle`) into a single array `y` using `np.concatenate`.  \n",
    "\n",
    "- Before concatenation, we had three separate 1-D arrays of shapes `(a,)`, `(b,)`, and `(c,)`.  \n",
    "- After concatenation, we obtain a single 1-D array of shape `(a+b+c,)`, which contains the labels for **all images combined** (circles, squares, and triangles).  \n",
    "\n",
    "The variable name `y` is the **convention in machine learning** again, to denote the array of **labels/targets** corresponding to the input data `X`.\n",
    "We name the combined image array **`X`** because, by convention in machine learning, `X` represents the **input data** (features) fed into a model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952179f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([y_circle, y_square, y_triangle], axis=0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8820e85",
   "metadata": {},
   "source": [
    "Now the NumPy arrays are prepared. We have:\n",
    "\n",
    "- A **stack of images**:\n",
    "  - The first *a* images are **circles**  \n",
    "  - The next *b* images are **squares**  \n",
    "  - The following *c* images are **triangles**\n",
    "\n",
    "- And a **label array**:\n",
    "  - The first *a* values are **0**  \n",
    "  - The next *b* values are **1**  \n",
    "  - The following *c* values are **2**  \n",
    "\n",
    "Keep in mind the correspondence between labels and classes:\n",
    "\n",
    "- **0 = circle**  \n",
    "- **1 = square**  \n",
    "- **2 = triangle**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05040a3",
   "metadata": {},
   "source": [
    "## 2- Prepare dataset for buiding Keras Tensorflow model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d96528",
   "metadata": {},
   "source": [
    "### 2-1- Add a Channel Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1741828",
   "metadata": {},
   "source": [
    "Our current data array `X` has the shape `(n_samples, 128, 128)`, which represents  \n",
    "`n_samples` grayscale images of size `128 × 128`.\n",
    "\n",
    "However, most **Keras/TensorFlow CNN layers** expect an input shape of  \n",
    "`(n_samples, height, width, channels)` — the last dimension corresponds to the number of channels  \n",
    "(e.g. `3` for RGB images, `1` for grayscale).\n",
    "\n",
    "In short, we will have to pass from `(n_samples, 128, 128)` to `(n_samples, 128, 128, 1)`\n",
    "\n",
    "\n",
    "To make our grayscale images compatible with CNNs, we need to **add a channel dimension** equal to `1`.  \n",
    "We can do this with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "X = X[:, :, :, np.newaxis]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd56747",
   "metadata": {},
   "source": [
    "### 2-2- Shuffle data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3c0fe",
   "metadata": {},
   "source": [
    "  Shuffling randomly mixes samples so that the order of data (e.g., all circles first, then all squares, then all triangles) does not bias the training process.  \n",
    "  This ensures that batches fed to the model are representative of all classes and helps the model learn better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ff6d5",
   "metadata": {},
   "source": [
    "#### 2-2-1- Set random seeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa4e56e",
   "metadata": {},
   "source": [
    "Setting seeds (for NumPy, Python’s `random`, TensorFlow, etc.) forces all random operations to produce the same sequence of random numbers each time you run the script.  \n",
    "this makes your data preparation and model training **reproducible** — you’ll get the same shuffled dataset and the same initial weights at every run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2dcbc",
   "metadata": {},
   "source": [
    "#### 2-2-2- Apply Shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344745c",
   "metadata": {},
   "source": [
    "Now use `sklearn.utils.shuffle` to randomly reorder `X` and `y` **in the same way** so that the correspondence between images and labels is preserved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695f28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X, y = shuffle(X, y, random_state=seed)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c7e49",
   "metadata": {},
   "source": [
    "### 2-3- Split Dataset into Training and Test Sets  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79033000",
   "metadata": {},
   "source": [
    "After shuffling, we split our dataset into **training** and **test** sets.  \n",
    "- The **training set** is used to train the CNN.  \n",
    "- The **test set** is used to evaluate its performance on unseen data.  \n",
    "\n",
    "We use `train_test_split` from `sklearn.model_selection`, with the following considerations:  \n",
    "- `test_size=0.2` → 20% of the data is reserved for testing.  \n",
    "- `random_state=seed` → ensures reproducibility.  \n",
    "- `stratify=y` → preserves the class proportions in both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suppose que X et y sont déjà construits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,         # 20% en test\n",
    "    random_state=seed,       # pour reproductibilité\n",
    "    stratify=y             # pour garder la proportion des classes\n",
    ")\n",
    "\n",
    "print(f\"Training set: X_train = {X_train.shape}, y_train = {y_train.shape}\")\n",
    "print(f\"Test set:     X_test  = {X_test.shape}, y_test  = {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d50be3b",
   "metadata": {},
   "source": [
    "## 3- Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de56fe9c",
   "metadata": {},
   "source": [
    "### 3-1 — Create a 2D CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247189ed",
   "metadata": {},
   "source": [
    "Now that the dataset is ready, we can define a **2D CNN** for classifying our images into three classes: circle, square, or triangle.  \n",
    "\n",
    "Our model uses the following layers:\n",
    "\n",
    "1. **Conv2D + ReLU** → Extracts spatial features from the images.  \n",
    "2. **MaxPooling2D** → Reduces spatial dimensions while keeping important features.  \n",
    "3. **Another Conv2D + ReLU** → Learns more complex patterns.  \n",
    "4. **MaxPooling2D** → Further reduces feature map size.  \n",
    "5. **Flatten** → Converts 2D feature maps into a 1D vector for the dense layers.  \n",
    "6. **Dense (64, ReLU)** → Fully connected layer to combine features.  \n",
    "7. **Dense (3, softmax)** → Output layer with 3 neurons for our 3 classes.  \n",
    "\n",
    "We compile the model using:  \n",
    "- **Optimizer:** `adam`  \n",
    "- **Loss function:** `sparse_categorical_crossentropy` (because our labels are integer-encoded)  \n",
    "- **Metric:** `accuracy` to monitor performance during training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(X.shape[1],X.shape[2],X.shape[3])),\n",
    "    #layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')  # 3 classes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fa4e4",
   "metadata": {},
   "source": [
    "### 3-2- Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10133138",
   "metadata": {},
   "source": [
    "**Training a model** means adjusting its internal parameters (weights and biases) so that it can learn to map input data (`X_train`) to the correct output labels (`y_train`).  \n",
    "During training, the model makes predictions on the input data, computes the error (loss) compared to the true labels, and updates its parameters using an optimization algorithm (here, **Adam**) to minimize this error.\n",
    "\n",
    "- **`X_train` and `y_train`**: the input images and their corresponding labels for training.  \n",
    "- **`epochs=20`**: the model will iterate 20 times over the entire training dataset.  \n",
    "- **`batch_size=64`**: the number of samples processed before the model updates its weights.  \n",
    "- **`validation_split=0.2`**: 20% of the training data is held out for validation to monitor performance during training.  \n",
    "- **`verbose=1`**: print progress and metrics for each epoch.\n",
    "\n",
    "The function returns a `history` object that stores the evolution of training and validation metrics over epochs, which can be used later for plotting learning curves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d670f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,          \n",
    "    epochs=20,                \n",
    "    batch_size=64,            \n",
    "    validation_split=0.2,      \n",
    "    verbose=1                 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a27072e",
   "metadata": {},
   "source": [
    "### 3-3- Evaluate model performances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147cf3e",
   "metadata": {},
   "source": [
    "#### 3-3-1- Plot metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8a1c27",
   "metadata": {},
   "source": [
    "After training, we can **visualize how the model’s performance evolved** over epochs.  \n",
    "Here, we plot the **training accuracy** and **validation accuracy** for each epoch.  \n",
    "\n",
    "- **Training accuracy** shows how well the model fits the training data.  \n",
    "- **Validation accuracy** shows how well the model generalizes to unseen data (here, a fraction of the training set held out for validation).  \n",
    "\n",
    "By comparing the two curves, we can detect **overfitting** (training accuracy much higher than validation) or **underfitting** (both accuracies low).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e355530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c817e08a",
   "metadata": {},
   "source": [
    "#### 3-3-2- Predictions on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa7aaf",
   "metadata": {},
   "source": [
    "##### 3-3-3-2- Compute prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e927fc7a",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can **make predictions on the test set**.  \n",
    "We will compute the predicted class for each test image by taking the class with the highest probability.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d6d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict(X_test)              # probability for each class (nb_images, 3)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)          # prdicted class (0 or 1 or 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab0c611",
   "metadata": {},
   "source": [
    "After predicting on the test set, `y_pred_proba` contains the **predicted probabilities for each class** for every image, while `y_pred` contains the **predicted class** based on the maximum probability.\n",
    "For example, for the first 5 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e458f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities for each class\n",
    "print(\"Predicted probabilities for the first 5 test images:\")\n",
    "for i, probs in enumerate(y_pred_proba[:5]):\n",
    "    print(f\"Image {i}: {probs}\")\n",
    "\n",
    "# Predicted class\n",
    "print(\"\\nPredicted classes for the first 5 test images:\")\n",
    "for i, pred in enumerate(y_pred[:5]):\n",
    "    print(f\"Image {i}: class {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e99e9",
   "metadata": {},
   "source": [
    "#### 3-3-3- Accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d55e10c",
   "metadata": {},
   "source": [
    "##### 3-3-3-1 — Compute Test Accuracy\n",
    "\n",
    "Once we have the predicted classes (`y_pred`) for the test set, we can measure how well our CNN performs using the **accuracy score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19efcadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# --- accuracy ---\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy on test set: {acc:.3f}\")\n",
    "print(f\"Meaning: {100*acc:.1f}% of the predictions are correct\")\n",
    "\n",
    "\n",
    "# print(f\"Accuracy on test : {acc:.3f}\")\n",
    "# print(f\"Meaning : {100*acc:.1f}% of good predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8b32d9",
   "metadata": {},
   "source": [
    "##### 3-3-3-1- Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e57e5",
   "metadata": {},
   "source": [
    "A **confusion matrix** is a table that summarizes the performance of a classification model by comparing the **true labels** `(y_test)` with the **predicted labels** `(y_pred)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c8482",
   "metadata": {},
   "source": [
    "We can visualize the confusion matrix as a **heatmap** to make it easier to interpret the model's performance.\n",
    "\n",
    "- Each **cell** shows the number of samples with a given true label (row) predicted as a given class (column).  \n",
    "- The **diagonal** shows the correctly classified samples.  \n",
    "- The **off-diagonal** shows misclassifications.  \n",
    "- Using colors (Blues) allows us to quickly see which classes are predicted well (darker = more samples).  \n",
    "\n",
    "The x-axis represents the **predicted classes**, the y-axis the **true classes**.  \n",
    "The **accuracy** of the model is also displayed in the title for quick reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3064a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['circle','square','triangle'],\n",
    "            yticklabels=['circle','square','triangle'])\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Matrice de confusion (Accuracy {acc:.2%})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e599c5cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec914a0d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "633127b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ecba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model : ton modèle Keras\n",
    "def model_size_and_params(model, dtype_size=4):\n",
    "    params = model.count_params()\n",
    "    # approx size in bytes (float32 = 4 bytes)\n",
    "    size_bytes = params * dtype_size\n",
    "    size_mb = size_bytes / (1024**2)\n",
    "    return params, size_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65825dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def file_size_mb(path):\n",
    "    \"\"\"Retourne la taille d’un fichier en MB\"\"\"\n",
    "    return os.path.getsize(path) / (1024 ** 2)\n",
    "\n",
    "circle_size   = file_size_mb(path_circle)\n",
    "square_size   = file_size_mb(path_square)\n",
    "triangle_size = file_size_mb(path_triangle)\n",
    "\n",
    "\n",
    "def measure_inference_time(model, input_shape, n_warmup=10, n_run=100):\n",
    "    # generate random input (batch size 1)\n",
    "    x = np.random.rand(1, *input_shape).astype(np.float32)\n",
    "    # warmup\n",
    "    for _ in range(n_warmup):\n",
    "        _ = model.predict(x, verbose=0)\n",
    "    # timed runs\n",
    "    t0 = time.time()\n",
    "    for _ in range(n_run):\n",
    "        _ = model.predict(x, verbose=0)\n",
    "    t1 = time.time()\n",
    "    avg_ms = (t1 - t0) / n_run * 1000\n",
    "    return avg_ms\n",
    "\n",
    "print(f\"Taille circle:   {circle_size:.2f} MB\")\n",
    "print(f\"Taille square:   {square_size:.2f} MB\")\n",
    "print(f\"Taille triangle: {triangle_size:.2f} MB\")\n",
    "print(f\"Taille totale:   {circle_size + square_size + triangle_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658d5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params, model_mb = model_size_and_params(model)\n",
    "print(\"Params:\", params)\n",
    "print(\"Model size (MB):\", model_mb)\n",
    "print(f\"Taille totale:   {circle_size + square_size + triangle_size:.2f} MB\")\n",
    "avg_infer_ms = measure_inference_time(model, X_train.shape[1:])\n",
    "print(\"Inference ms:\", avg_infer_ms)\n",
    "# training time demo (1 epoch)\n",
    "\n",
    "t0 = time.time()\n",
    "model.fit(X_train[:128], y_train[:128], epochs=1, batch_size=8, verbose=1)\n",
    "print(\"1 epoch time (s):\", time.time()-t0)\n",
    "import psutil, os\n",
    "print(\"Process RSS (MB):\", psutil.Process(os.getpid()).memory_info().rss / 1024**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vID.end(cwd0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donnees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
